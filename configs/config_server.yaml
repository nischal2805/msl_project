# ============================================
# ISL Real-Time Translation - A100 SERVER CONFIG
# ============================================
# Optimized for: NVIDIA A100 GPU (40GB/80GB)
# Training: Full iSign v1.1 dataset (127K samples)
# Target: Samsung Galaxy Tab S9 deployment

# Model Architecture (same as local)
model:
  encoder:
    backbone: "mobilenetv3_large"
    pretrained: true
    freeze_epochs: 5           # Freeze backbone for first 5 epochs
    output_dim: 512
  
  temporal:
    num_queries: 32            # Compress video to 32 tokens
    num_heads: 8
    num_temporal_conv: 2       # Number of temporal conv blocks
    kernel_size: 3
    dropout: 0.1
  
  decoder:
    hidden_dim: 512
    num_layers: 4
    num_heads: 8
    ff_dim: 1024               # Balanced size for ~51M params
    dropout: 0.1
    max_len: 100               # Maximum output sequence length

# Training Hyperparameters - OPTIMIZED FOR A100
training:
  # Batch settings - A100 can handle larger batches
  batch_size: 64               # Larger batch for A100 (40GB VRAM)
  gradient_accumulation: 2     # Effective batch = 64 * 2 = 128
  num_epochs: 50
  
  # Optimizer settings (separate LRs for encoder/decoder)
  encoder_lr: 1.0e-4           # Lower LR for pretrained backbone
  decoder_lr: 3.0e-4           # Higher LR for randomly initialized decoder
  weight_decay: 0.01
  warmup_ratio: 0.1            # 10% of total steps for warmup
  
  # Loss weights
  ctc_weight: 0.3              # CTC loss weight (for streaming output)
  ce_weight: 0.7               # Cross-entropy weight (main loss)
  label_smoothing: 0.1         # Prevents overconfidence
  
  # Gradient clipping
  max_grad_norm: 1.0
  
  # Early stopping
  patience: 10                 # Stop if no improvement for 10 epochs
  
  # Checkpointing
  save_every_n_epochs: 5       # Save checkpoint every 5 epochs
  keep_last_n_checkpoints: 3   # Keep last 3 checkpoints
  
  # Mixed precision training - CRITICAL for A100 performance
  use_amp: true
  
  # Resume training
  resume_from: null            # Set to checkpoint path to resume

# Data Configuration - A100 SERVER PATHS
data:
  # SERVER PATHS
  video_dir: "/media/rvcse22/CSERV/kortex_sem5/surya/videos/train"
  csv_path: "/media/rvcse22/CSERV/kortex_sem5/new/ISL_TRANSLATION/iSign_v1.1.csv"
  
  num_frames: 16               # Frames to sample per video
  image_size: 224              # Input image size
  num_workers: 8               # More workers for faster data loading on server
  
  # Data splits (by VIDEO_ID, not uid - prevents data leakage)
  train_split: 0.8             # 80% for training (~5,000 videos, ~100K segments)
  val_split: 0.1               # 10% for validation (~625 videos, ~12K segments)
  test_split: 0.1              # 10% for testing (~625 videos, ~12K segments)

# Tokenizer Configuration
tokenizer:
  name: "bert-base-uncased"
  bos_id: 101                  # [CLS] token
  eos_id: 102                  # [SEP] token
  pad_id: 0                    # [PAD] token

# Inference Configuration
inference:
  temperature: 0.8             # Sampling temperature
  beam_size: 4                 # For beam search
  length_penalty: 1.0          # Length penalty for beam search

# Logging
logging:
  log_every_n_steps: 100       # Log more frequently with large dataset
  wandb:
    enabled: false             # Set to true if you have wandb
    project: "isl-translation"
    entity: null

# Export Configuration (for mobile deployment)
export:
  onnx:
    opset_version: 14
    dynamic_axes: true
  tflite:
    quantization: "int8"       # int8 quantization for mobile (~20MB)

# Paths - SERVER
paths:
  checkpoint_dir: "checkpoints"
  log_dir: "logs"
  export_dir: "exports"
